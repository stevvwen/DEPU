name: ae_ddpm

ae_model:
  _target_: core.module.modules.encoder.medium
  in_dim: 3715
  input_noise_factor: 0.1
  latent_noise_factor: 0.2

#     _target_: core.module.modules.autoencoder.Latent_AE_cnn_small
#     in_dim: 2048

model:
  arch:
    _target_: core.module.wrapper.ema.EMA
    model:
      _target_: core.module.modules.unet.AE_CNN_bottleneck
      in_channel: 1
      in_dim: 20


beta_schedule:
  start: 1e-4
  end: 2e-2
  schedule: linear
  n_timestep: 1000

model_mean_type: eps
model_var_type: fixedlarge
loss_type: mse

train:
  split_epoch: 400
#   split_epoch: 0
  optimizer:
    _target_: torch.optim.AdamW
    lr: 1e-3
    weight_decay: 2e-6

  ae_optimizer:
    _target_: torch.optim.AdamW
    lr: 1e-3
    weight_decay: 2e-6

  lr_scheduler:

  trainer:
    _target_: pytorch_lightning.Trainer
    _convert_: all
    max_epochs: 1000
    check_val_every_n_epoch: 50
    val_check_interval : null
    log_every_n_steps: 10
    limit_val_batches: 1
    limit_test_batches: 1
    devices:
      - ${device.id}

    enable_model_summary: false

    callbacks:
    - _target_: pytorch_lightning.callbacks.ModelCheckpoint
      monitor: 'best_g_acc'
      mode: 'max'
      save_top_k: 1
      save_last: true
      filename: 'ddpm-{epoch}-{best_g_acc:.4f}'

#     - _target_: pytorch_lightning.callbacks.ModelCheckpoint
# #       dirpath: ${output_dir}/${system.name}/checkpoints
#       filename: "ae-{epoch}-{loss:.4f}"
#       monitor: 'ae_loss'
#       mode: 'min'
#       save_top_k: 1
#       save_last: false
#       verbose: true

    - _target_: pytorch_lightning.callbacks.ModelCheckpoint
#       dirpath: ${output_dir}/${system.name}/checkpoints
      filename: "ae-{epoch}-{ae_acc:.4f}"
      monitor: 'ae_acc'
      mode: 'max'
      save_top_k: 1
      save_last: false
      verbose: true

    logger:
      _target_: pytorch_lightning.loggers.TensorBoardLogger
      save_dir: ${output_dir}/${system.name}/
      name: '.'
      version: '.'