import os
import glob
from sqlalchemy import Null
import torch
from core.utils.utils import get_storage_usage
from core.utils.format import config_to_dict


training_layers= ["policy1.weight", 
"policy1.bias",
"policy2.weight",
"policy2.bias",
"policy3.weight",
"policy3.bias",
"q1_layer1.weight",
"q1_layer1.bias",
"q1_layer2.weight",
"q1_layer2.bias",
"q1_layer3.weight",
"q1_layer3.bias",
"q2_layer1.weight",
"q2_layer1.bias",
"q2_layer2.weight",
"q2_layer2.bias",
"q2_layer3.weight",
"q2_layer3.bias"]

cfg= {"cfg": {"agent": {"agent_name": "td3", "agent": {"_target_": "agents.td3.TD3Agent", "obs_shape": [3], "act_shape": [1], "act_limit_low": -2.0, "act_limit_high": 2.0, "device": "cuda:0", "lr": 0.001, "hidden_dim": 32, "critic_target_tau": 0.01, "num_expl_steps": 2000, "update_every_steps": 2, "stddev_schedule": "linear(0.5,0.05,5000)", "stddev_clip": 0.3, "discount": 0.99}}, "rl_env": {"env_name": "Pendulum-v1", "env_kwargs": {"g": 10.0}, "max_steps": 100000}, "name": "rl", "seed": 30, "debug_mode": True, "eval_mode": False, "eval_interval": 1000, "num_agents": 200, "device": {"cuda_visible_devices": "0,1,2,3,4,5,6", "id": 0, "cuda": "cuda:0"}, "replay_buffer": {"_target_": "core.utils.replay_memory.ReplayMemory", "capacity": 100000, "seed": 30}, "batch_size": 256, "save_root": "param_data", "train_layer": "all", "data": {"data_root": "data/rl", "dataset": "Pendulum-v1", "batch_size": 64, "num_workers": 1}, "param": {"data_root": "param_data/Pendulum-v1/data.pt", "k": 200, "num_workers": 4}, "load_system_checkpoint": Null}, 
      "performance": [-121.63981276746993, -238.04413577211935, -134.78758730642363, -165.51400248921232, -127.0666417627561, -142.6007166575791, -118.98997998032053, -161.45933097748878, -232.7925350798754, -127.7427406119586, -151.80550067420484, -192.5800903317172, -192.6014470192346, -236.55156426215697, -122.79790747221885, -121.43899527904891, -161.82364369058885, -122.53513694539781, -176.62003509854063, -194.88702294167555, -197.4150170030731, -119.26618815035833, -165.33425445062, -193.0097907137574, -155.68014529478378, -162.46022260806453, -198.2731359213022, -168.04803983477007, -212.7469743795824, -120.60076908857616, -159.20222010400445, -176.22882708820364, -124.97489861733574, -122.32598550994601, -206.14814042686874, -152.66835473156624, -80.03874882902429, -125.74048129922208, -126.47406376326207, -90.94713732239103, -162.9779043006992, -82.06205436472244, -164.47545417144536, -173.17296295457922, -121.19607583828999, -158.08072756189623, -126.93043249244981, -174.9739112136747, -194.66025966247045, -205.07245266789673, -202.3834630897562, -125.62898077124368, -243.88463820493067, -162.25860282490183, -123.6022747045807, -83.61819550498349, -120.60645627175403, -127.35657501643095, -194.37908710366173, -158.66319547226638, -206.16657435735567, -170.75824137483326, -122.87578082038522, -123.05839129297829, -154.6731587532385, -94.98985624096201, -164.8181586217939, -191.2839367514533, -82.57189667178135, -162.96582396878895, -83.71320273109674, -99.28151973756155, -117.41055046472115, -82.34649979241689, -83.38914299100098, -183.22255323277943, -197.82212240279515, -150.90163177411813, -130.3977785659542, -89.02855683110876, -161.99448760783596, -159.78933073681966, -155.45301489743187, -150.96817776927915, -124.25388739539706, -198.51973688276655, -92.7742035608789, -195.9208865049459, -84.63040593354243, -196.4103016097097, -247.68467239923595, -157.38765767511862, -85.1097586708422, -161.02496311659817, -157.8324974097113, -184.84585160093494, -79.75591931360691, -85.13109279336474, -121.7029131605891, -85.27191882191899, -122.12410807303229, -129.2321739330827, -234.41218989540732, -119.11623047528114, -124.35119716163125, -161.0518389773046, -201.59015889949475, -237.18342198057817, -123.52085765337146, -185.48462046057088, -155.89580601844852, -45.265147675114264, -57.1442548491868, -226.0838790786673, -83.96840026285606, -142.7054671213252, -79.87069667053046, -138.1003905281266, -241.73580989890513, -164.8122695710852, -124.71789593179614, -78.46766883236602, -120.1281070359798, -158.66016136875012, -209.1876213182245, -164.83266462844844, -86.23733806089133, -43.048581168750395, -122.9110015413541, -160.71793258894772, -129.71259463370262, -121.9409930998479, -173.2489170434724, -155.0452339453884, -241.40307667383283, -134.05031201399729, -142.60344202637157, -152.52322164355041, -248.13092562047373, -116.0712485535683, -84.63058181640051, -229.4052773727776, -159.5485647259057, -40.34448682524421, -174.59653888394698, -131.00302852242572, -183.66057631711445, -122.7206309932425, -154.9891066954518, -84.69928294264597, -170.02931894848527, -134.98284861227884, -208.8171459697036, -158.54446677101507, -81.73549538097991, -152.37752313777506, -169.23149479657266, -120.0619992703671, -126.10544947156592, -122.5212580692186, -83.77749999941865, -125.3428661799533, -217.21925257865564, -205.73886440003147, -156.54044313713953, -129.71445887128783, -80.7746428078115, -42.71766108620395, -246.25668489696224, -127.18830307657277, -103.14571022814147, -244.68533312802558, -229.3758088764946, -126.65787936201747, -162.4562359762642, -201.4335122561187, -167.20710047380572, -116.22280320649963, -202.36566758053164, -162.13538411055885, -154.63281213647247, -160.81731989416, -83.68491949959247, -157.5225451476135, -128.749908227439, -120.20094401136704, -160.9428540590557, -79.52339908831551, -84.97306362530847, -189.3739788751673, -119.88403836613064, -242.8836343265151, -159.58475208088623, -89.01061913178164, -227.95595284474948, -83.05355644111391, -163.15930932057114, -81.61927715288498, -182.76106004277298, -161.93731101187933]}




tmp_path= "param_data/tmp_250414_180816"

pdata = []
for file in glob.glob(os.path.join(tmp_path, "p_data_*.pt")):
    buffer = torch.load(file)
    param = []
    for key in buffer.keys():
        if key in training_layers:
            param.append(buffer[key].data.reshape(-1))
    pdata.append(torch.cat(param, 0))

batch = torch.stack(pdata)
mean = torch.mean(batch, dim=0)
std = torch.std(batch, dim=0)

useage_gb = get_storage_usage(tmp_path)
print(f"path {tmp_path} storage usage: {useage_gb:.2f} GB")

state_dic = {
    'pdata': batch.cpu().detach(),
    'mean': mean.cpu(),
    'std': std.cpu(),
    'train_layer': training_layers,
    'performance': cfg['performance'],
    'cfg': cfg
}
torch.save(state_dic, os.path.join("param_data/Pendulum-v1", "data.pt"))